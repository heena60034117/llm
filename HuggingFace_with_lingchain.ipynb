{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374dfb3d-b252-4820-abe6-fc61894358d6",
   "metadata": {},
   "source": [
    "# Required Modules\n",
    "!pip install huggingface_hub\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84f11f6-8cf6-4dc6-9637-b6dea8db36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4eb120-6357-4d67-848c-d290f1f843fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']='KEYS'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6f91c-f508-4dbd-a434-793ea18c99cb",
   "metadata": {},
   "source": [
    "# Text2Text Generation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda33233-6613-432e-9e35-54fabb7baf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"what is a good name for a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66394ce4-27ab-4b28-954e-10a57a36766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_client = HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={'temperature':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7bf3ab-df00-4439-840d-9c44e2fc85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=hugging_client, prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "741da358-f53b-4016-b8f7-8a3765115337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paper Mills'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803b806-3f60-4844-b856-560933e75def",
   "metadata": {},
   "source": [
    "# pipeline and use model on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "020b18fe-1b60-4925-ba91-6712923896ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb23463-f78a-468d-8135-4782fe2f2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'google/flan-t5-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5848fdb-fec2-4022-a0d0-d9d713920c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas\\anaconda3\\envs\\GenAI\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9f3b4c7-2277-4c06-8716-a03815f7cacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72c7dd98-c650-42ed-ab6d-816ee9c409d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78edf6b8-fe0a-4613-97fc-f89f993c67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0a64349-9666-4fe1-a4c2-3a7718d4ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=[\"name\"],\n",
    "    template=\"can you tell me about footballer {name}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e908872-caf9-4bcd-a399-49c4ddd73045",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=local_llm, prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea378c9e-5b05-42f8-b2a1-826bb8fa12bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He played for the Indian national football team'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"dhyanchand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "138094e6-23af-4046-83e9-a6e9ed4afd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Messi is a footballer from Argentina .'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e47c70-f7ef-40f7-a6e5-5265c62a51db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b417d1d-691b-4be6-813f-22f28f739bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7394cea-8f7d-4a32-918b-fd704beecdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8078577-25fa-4ef4-b55e-712fa58f982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73900cfb-4411-4ee4-acc3-78687e4da95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader1 = PyPDFLoader(r\"C:\\xampp\\htdocs\\GenAI_BOT\\newsletters\\appendix9-single-unit-newsletter.pdf\")\n",
    "pages1 = loader1.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0793aa0f-73bb-447f-964b-596144872c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = pages1[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25a8ea6c-fca8-49cc-86cb-bc620f42a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_tweeter_newsletter = PromptTemplate(\n",
    "    input_variables=[\"newsletter\"],\n",
    "    template=\"Provide me creative post for twitter with in 43 words and 280 characters, on basis of below content: {newsletter}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29a9dc55-22e1-4bc9-ab56-89186fb55abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=local_llm, prompt=prompt_template_tweeter_newsletter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cd3a1d7-5de0-4141-a371-13a56a247a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SINGLE UNIT TRANSFUSION GUIDELIN E Issue # Single Unit Transfusion Guidel ine PART OF A RESTRICTIV E TRANSFUSION STRATEGY PATIENT BLOOD MANAGE MENT GUIDELINE S The Single Unit Transfusion Guideline developed by the National Blood Authority, Australia is intended for use by all clinicians responsible for prescribing blood transfusion to patients who are not bleeding and not in an operating theatre. Blood transfusion is a live tissue transplant.\n"
     ]
    }
   ],
   "source": [
    "def get_first_20_words(text):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Extract the first 20 words\n",
    "    first_20_words = ' '.join(words[:74])\n",
    "\n",
    "    return first_20_words\n",
    "\n",
    "# Example usage:\n",
    "input_string = pages1[0].page_content\n",
    "result = get_first_20_words(input_string)\n",
    "print(result[32:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52642425-7beb-443a-be30-78cc65322ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SINGLE UNIT TRANSFUSION GUIDELIN E Issue # Single Unit Transfusion Guidel ine PART OF A RESTRICTIV E TRANSFUSION STRATEGY PATIENT BLOOD MANAGE MENT GUIDELINE S The Single Unit Transfusion Guideline developed by the National Blood Authority, Australia is intended for use by all clinicians responsible for prescribing blood transfusion to patients who are not bleeding and not in an operating theatre. Blood transfusion is a live tissue transplant.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(result[32:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3713d-da2f-4a87-93a8-faeda2168f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
